# Gesture-Detection-Neural-Network
For my first project using artificial intelligence, I decided to create a gesture detection project that uses the AI branch of 
machine learning. With this, I was able to sit in front of a camera, and my computer would be able to tell me if I was sitting 
with no hands in the frame of the camera, my right hand showing, or my left hand showing. In order to do this, I had to train a 
neural network with examples of my own. I made a recording with my right hand up, my left hand up, and with me sitting with no hands up. 
In total, I gave the neural network 36 examples. After that, I let the program run, and it was able to determine whether I had my right 
hand up, my left hand, or if I was sitting with no hands up. Once it determined my position, it showed me a picture of myself in the 
same position (e.g. if I had my right hand up, it showed me a picture of myself in which I had my right hand up). This replicate 
used the branch Computer Vision as well, as it used a webcam to 'see me'. I used the softwares Processing, and Webkinator for this. If you would like to do this project yourself, take a look at the tutorial here: https://maker.pro/custom/projects/machine-learning-for-makers-how-to-use-machine-learning-to-recognize-gestures
